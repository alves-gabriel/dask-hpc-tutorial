{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492e6092-160d-4eb6-914e-de8ba199f847",
   "metadata": {},
   "source": [
    "# Dask for Distributed Computing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fd0e1b-63b8-4cfe-806c-4b0841fa6312",
   "metadata": {},
   "source": [
    "## Introduction and installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46deabe-c125-4543-add1-b04df2a4b10f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scene__Default Scene": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- Colors: https://encycolorpedia.com/-->\n",
       "<!-- Comments ommited due to a bug in Jupyter-->\n",
       "\n",
       "<style>\n",
       "\n",
       "    a:link { \n",
       "        color: #0000EE; \n",
       "    }\n",
       "    a:visited { \n",
       "        color: #551A8B; \n",
       "    }\n",
       "    a:active { \n",
       "        color: #EE0000; \n",
       "    }\n",
       "\n",
       "    h1 { \n",
       "        font-size: 30px; \n",
       "        color: rgba(220, 20, 60, 1) !important;  \n",
       "    }\n",
       "\n",
       "    h2 {\n",
       "     font-size: 25px;\n",
       "     color: rgba(255, 140, 0, 1); /* Orange */\t\t \n",
       "    }\t \n",
       "\n",
       "    h3 {\n",
       "     font-size: 20px;\n",
       "     color:rgba(204, 85, 0, 1); /* Dark orange */\t\t \n",
       "    }\t \n",
       "        \n",
       "    td {\n",
       "      text-align: center;\n",
       "    }\n",
       "\n",
       "    div.highlight_red {    \n",
       "        background-color: rgba(179, 0, 0, .1);\n",
       "        background-opacity : 0.5;\n",
       "        }\n",
       "\n",
       "    div.highlight_red .title_box {\n",
       "        background-color: rgba(179, 0, 0, .6);\n",
       "        width: 100%;\n",
       "    }\n",
       "\n",
       "    div.highlight_green {    \n",
       "        background-color: rgba(\t19, 98, 7, .1);\n",
       "        background-opacity : 0.5;\n",
       "        }\n",
       "\n",
       "    div.highlight_green .title_box {\n",
       "        background-color: rgba(\t19, 130, 7, .6);\n",
       "        width: 100%;\n",
       "    }\n",
       "\n",
       "    div.highlight_turquoise {    \n",
       "        background-color: rgba(\t40, 154, 164, .1);\n",
       "        background-opacity : 0.5;\n",
       "        }\n",
       "\n",
       "    div.highlight_turquoise .title_box {\n",
       "        background-color: rgba(\t40, 154, 164, .6);\n",
       "        width: 100%;\n",
       "    }\n",
       "\n",
       "    div.highlight_purple {    \n",
       "        background-color: rgba(120, 81, 169, .1);\n",
       "        background-opacity : 0.5;\n",
       "        }\n",
       "\n",
       "    div.highlight_purple .title_box {\n",
       "        background-color: rgba(120, 81, 169, .6);\n",
       "        width: 100%;\n",
       "    }\n",
       "\n",
       "    div.highlight_blue {    \n",
       "        background-color: rgba(\t65, 105, 225, .1);\n",
       "        background-opacity : 0.5;\n",
       "    }\n",
       "\n",
       "    div.highlight_blue .title_box {\n",
       "        background-color: rgba(\t65, 105, 225, .6);\n",
       "        width: 100%;\n",
       "    }\n",
       "\n",
       "    .title{\n",
       "        text-indent: 1%;\n",
       "        padding: .25em;\n",
       "        font-weight: bold;\n",
       "        font-size: 18px;\n",
       "        color : white;\n",
       "    }\n",
       "\n",
       "    .content{\n",
       "        text-indent: 2%;\n",
       "        padding: 1em;\n",
       "        font-size: 14px;\n",
       "    }\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!-- Colors: https://encycolorpedia.com/-->\n",
    "<!-- Comments ommited due to a bug in Jupyter-->\n",
    "\n",
    "<style>\n",
    "\n",
    "    a:link { \n",
    "        color: #0000EE; \n",
    "    }\n",
    "    a:visited { \n",
    "        color: #551A8B; \n",
    "    }\n",
    "    a:active { \n",
    "        color: #EE0000; \n",
    "    }\n",
    "\n",
    "    h1 { \n",
    "        font-size: 30px; \n",
    "        color: rgba(220, 20, 60, 1) !important;  \n",
    "    }\n",
    "\n",
    "    h2 {\n",
    "     font-size: 25px;\n",
    "     color: rgba(255, 140, 0, 1); /* Orange */\t\t \n",
    "    }\t \n",
    "\n",
    "    h3 {\n",
    "     font-size: 20px;\n",
    "     color:rgba(204, 85, 0, 1); /* Dark orange */\t\t \n",
    "    }\t \n",
    "        \n",
    "    td {\n",
    "      text-align: center;\n",
    "    }\n",
    "\n",
    "    div.highlight_red {    \n",
    "        background-color: rgba(179, 0, 0, .1);\n",
    "        background-opacity : 0.5;\n",
    "        }\n",
    "\n",
    "    div.highlight_red .title_box {\n",
    "        background-color: rgba(179, 0, 0, .6);\n",
    "        width: 100%;\n",
    "    }\n",
    "\n",
    "    div.highlight_green {    \n",
    "        background-color: rgba(\t19, 98, 7, .1);\n",
    "        background-opacity : 0.5;\n",
    "        }\n",
    "\n",
    "    div.highlight_green .title_box {\n",
    "        background-color: rgba(\t19, 130, 7, .6);\n",
    "        width: 100%;\n",
    "    }\n",
    "\n",
    "    div.highlight_turquoise {    \n",
    "        background-color: rgba(\t40, 154, 164, .1);\n",
    "        background-opacity : 0.5;\n",
    "        }\n",
    "\n",
    "    div.highlight_turquoise .title_box {\n",
    "        background-color: rgba(\t40, 154, 164, .6);\n",
    "        width: 100%;\n",
    "    }\n",
    "\n",
    "    div.highlight_purple {    \n",
    "        background-color: rgba(120, 81, 169, .1);\n",
    "        background-opacity : 0.5;\n",
    "        }\n",
    "\n",
    "    div.highlight_purple .title_box {\n",
    "        background-color: rgba(120, 81, 169, .6);\n",
    "        width: 100%;\n",
    "    }\n",
    "\n",
    "    div.highlight_blue {    \n",
    "        background-color: rgba(\t65, 105, 225, .1);\n",
    "        background-opacity : 0.5;\n",
    "    }\n",
    "\n",
    "    div.highlight_blue .title_box {\n",
    "        background-color: rgba(\t65, 105, 225, .6);\n",
    "        width: 100%;\n",
    "    }\n",
    "\n",
    "    .title{\n",
    "        text-indent: 1%;\n",
    "        padding: .25em;\n",
    "        font-weight: bold;\n",
    "        font-size: 18px;\n",
    "        color : white;\n",
    "    }\n",
    "\n",
    "    .content{\n",
    "        text-indent: 2%;\n",
    "        padding: 1em;\n",
    "        font-size: 14px;\n",
    "    }\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc33458-b9b2-44db-8a61-9786895d9193",
   "metadata": {},
   "source": [
    "<div class=\"highlight_blue\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ☞ Summary\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "\n",
    "We provide a short tutorial on <a href=\"https://docs.dask.org/en/stable/\" >Dask</a>, a Python library for parallel & distributed computing. In short, Dask is a **very pythonic** way of employing distributed computing and scaling common numerical libraries, such as ```numpy```. Some convenient functionalities, include:\n",
    "\n",
    "- A very numpy/pandas-like behavior and syntax for many of its main functionalities\n",
    "- Handling of very large objects and parallel computations, such as very large matrices or computationally expensive loops...\n",
    "- ... with little overhead, due to the lazy handling of arrays and computations. The framework is very pythonic and scalable, being easy to adapt even for existing code.\n",
    "- This means that one can handle large data even on lower-end systems, such as laptops, defining _Local Clusters_.\n",
    "- Similarly, Dask is also very convenient in HPC environments, where it can be used as a scheduler. It integrates into the existing python workflow very seamlessly: one is often able to parallelize existing codebases with very little effort.\n",
    "- Dask also comes with its own data structures and data types, which might be very convenient\n",
    "- Helpful dashboard for debugging and monitoring\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe4af54-40cc-465b-9445-124e4ab700fb",
   "metadata": {},
   "source": [
    "From <a href=\"https://docs.dask.org/en/stable/why.html#:~:text=Dask%20can%20enable%20efficient%20parallel,it%20doesn't%20have%20to.\">why Dask?</a>: \n",
    "\n",
    "> \"Moreover, Dask is co-developed with these libraries to ensure that they evolve consistently, minimizing friction when transitioning from a local laptop, to a multi-core workstation, and then to a distributed cluster. Analysts familiar with Pandas/Scikit-Learn/Numpy will be immediately familiar with their Dask equivalents, and have much of their intuition carry over to a scalable context.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "310a3cdc-7f97-4e4f-b708-1f3429d8fd8a",
   "metadata": {},
   "source": [
    "The jargon here probably will not make much sense now, but feel free to come back to these diagrams anytime. When using Dask, we will basically be dealing with three data types (depending on how you count it):\n",
    "\n",
    "- Usual types and data strctures from Python and its libraries: ints, floats, numpy arrays, lists and so on.\n",
    "- The two types which fall under the umbrella of the **low-level API**:\n",
    "  - **Delayed objects** -- which are lazy evatuations/task graphs which are only computed when necessary/desired -- greatly saving memory and computation time if properly managed.\n",
    "  - **Futures** -- which work more or less as tokens or pointers to asynchronous computations running in the background. Instructions can be given to these functions, and they are performed only when the underlying computations have been completed -- this eliminates the need of \"manually\" checking whether the dependencies necessary for a given calculations have been done or not, greatly simplifying the workflow. This is useful for interactive and real-time computations.\n",
    "- Types which fall under the umbrella of the **hight-level API**, namely objects such as **Dask arrays**. **dataframes** and so on -- which are based on their numpy/pandas counterpart and provide a high-level abstraction for these data types within the Dask framework.\n",
    "\n",
    "This is illustrated in the diagram below:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "<img src=\"images/dask_objects.png\" alt=\"Dask Types\">\n",
    "</div>\n",
    "\n",
    "One can always easily convert between these types and paralellize (or gather) computations using the interfaces in Dask. We will see this in detail in the upcoming sections, but we give a graphical summary here for reference. Note how within this framework we have ideas such as the notion of [MapReduce](https://en.wikipedia.org/wiki/MapReduce) in our workflow:\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "<img src=\"images/dask_objects_conversion.png\" alt=\"Dask Types Conversion\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d26209-1e30-41c2-a392-ed5186d1d077",
   "metadata": {},
   "source": [
    "#### ⚙️ Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d7adb-3898-4d86-8be5-a0f7078b4f94",
   "metadata": {},
   "source": [
    "Although you can run and test many of these functions on your local machine, it would be ideal to already do that inside the login or interactive node of a cluster. One should do port-forwarding through (i) a port for Jupyter-lab and (ii) another one for the dashboard functionalities in Dask. This is done through ports ```8888``` and ```8787```, respectively (by default):\n",
    "\n",
    "```\n",
    "ssh -L 8888:localhost:8888 -L 8787:localhost:8787 -J user@gate-adress.com user@adress.com\n",
    "```\n",
    "\n",
    "We start by importing some libraries and making the necessary installations. Note that dask, or at least some other tools and dependencies such as \n",
    "<a href=\"https://www.open-mpi.org\">open MPI</a> and <a href=\"https://mpi4py.readthedocs.io/en/stable/tutorial.html\">mpi4py</a>, might be already available on the Cluster (if that is your case).\n",
    "\n",
    "```\n",
    "conda create -n dask_env\n",
    "conda activate dask_env\n",
    "conda install dask dask-jobqueue dask-mpi mpi4py -c conda-forge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ce285-5a99-4157-8696-7ef948911b27",
   "metadata": {},
   "source": [
    "<div class=\"highlight_green\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ❐ Packages\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "\n",
    "We have installed four packages here:\n",
    "\n",
    "- <a href=\"https://www.dask.org\">Dask</a>, the base library \n",
    "- <a href=\"https://www.dask.org\">Dask-Jobqueue</a>, a Dask package for deployment in typical queuing systems found in HPC, such as SLURM \n",
    "- <a href=\"https://mpi.dask.org/en/latest/index.html\">Dask-mpi</a>, an interface between Dask and existing MPI environments. Finally, we install mpi4py as a prerequisite (if necessary, since it is often included in many HPC systems)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d6713-8860-4d8d-abe1-ebe7aef4b10e",
   "metadata": {},
   "source": [
    "#### First glance: dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e299c954-8c64-44f3-9a33-83f5eb4bf5cd",
   "metadata": {
    "scene__Default Scene": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd4390f-4a13-474d-ba08-4add4957e423",
   "metadata": {},
   "source": [
    "As mentioned above, Dask has many convenient capabilities, such as dealing with <a href=\"https://examples.dask.org/array.html\">Dask arrays</a>, which helps us manipulating very large arrays through chunks. We take this as a first example of the features of this library:  \n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "<img src=\"images/dask_array.png\" alt=\"Dask Array\">\n",
    "</div>\n",
    "\n",
    "Also note how it inherits, by design, much of the syntax from ```numpy```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c6bb04-5859-43b3-aebb-c107a426c9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 762.94 MiB </td>\n",
       "                        <td> 320.43 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (10000, 10000) </td>\n",
       "                        <td> (7000, 6000) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 6 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"120\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"72\" y1=\"0\" x2=\"72\" y2=\"120\" />\n",
       "  <line x1=\"96\" y1=\"0\" x2=\"96\" y2=\"120\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >10000</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">10000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<random_sample, shape=(10000, 10000), dtype=float64, chunksize=(7000, 6000), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The chunk sizes must add up to the dimension of the full matrix\n",
    "partitioned_array = da.random.random((10000, 10000), chunks=((7000, 3000), (6000, 2000, 2000)))\n",
    "partitioned_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533c53a-0282-4e1b-b89a-6f96decb7503",
   "metadata": {},
   "source": [
    "We can access these chunks individually, if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573b0114-3967-430e-ba42-545c13828b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 106.81 MiB </td>\n",
       "                        <td> 106.81 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (7000, 2000) </td>\n",
       "                        <td> (7000, 2000) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 1 chunks in 2 graph layers </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"93\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"43\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"43\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"43\" y1=\"0\" x2=\"43\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 43.37894337633637,0.0 43.37894337633637,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"21.689472\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2000</text>\n",
       "  <text x=\"63.378943\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,63.378943,60.000000)\">7000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<blocks, shape=(7000, 2000), dtype=float64, chunksize=(7000, 2000), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitioned_array.blocks[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463f685-6fc3-45c9-80e5-1025cdb47b43",
   "metadata": {},
   "source": [
    "## A first example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eca3a4-aaca-48f2-bc4e-12a9e1bc7320",
   "metadata": {},
   "source": [
    "### The scheduler: dask_jobqueue and single-node processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71767a38-04dd-4afd-8b64-543f5929815c",
   "metadata": {},
   "source": [
    "<div class=\"highlight_green\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ❐ Relevant documentation\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "<ul>\n",
    "    <li>Check the documentation for <a href =\"https://jobqueue.dask.org/en/latest/index.html\">jobqueue</a>, with an explanation on <a href=\"https://jobqueue.dask.org/en/latest/howitworks.html\">how it works</a> on the background and the <a href=\"https://jobqueue.dask.org/en/latest/configuration.html\">configuration</a>. For SLURM Clusters in particular, see <a href=\"https://jobqueue.dask.org/en/latest/generated/dask_jobqueue.SLURMCluster.html\">this link</a>.</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf8ecd8-0146-48c7-bf89-c60d7601982c",
   "metadata": {},
   "source": [
    "The simplest way of using Dask is probably to paralellize single-node process. Basically, what we will be doing now is use Dask to aid us in scheduling a bunch of different processes which do _not_  communicate with each other directly and operate asynchroniously. For that, we will basically set up a bunch of parameters for jobs which will be sent to the cluster. Dask will then be responsible for organizing and submiting everything through a scheduler, such as SLURM, which we will be using here. \n",
    "\n",
    "- More concretely, we can start by defining the number of _cores_ and number of _processes_ which will be used **in a single job**, as well as the total number of concurrent _jobs_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac96ba62-efea-40a8-bcd7-b5dc70bff29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cores = 72\n",
    "n_processes = 4\n",
    "n_jobs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4336ab-3295-4483-9338-e16dd44ca1f1",
   "metadata": {},
   "source": [
    "The number of cores per process is then just ```n_cores```/```n_processes```. Thus, in our example, each \"task\" would have 18 cpus available. With that in mind, we can use the ```SLURMCluster``` class from  ```dask_jobqueue```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aa584b4-e34f-4130-8147-74d5687e3ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/alvesgo/conda-envs/default_env/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 39761 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# The number of cores/processes should not go beyond the capabilities of a single node/macine!\n",
    "\n",
    "cluster = SLURMCluster(cores=n_cores                  # Total number of Kernels in the job\n",
    "                       , processes = n_processes      # Number of Python processes to cut up each job. This will be de number of workers PER JOB\n",
    "                       , memory=\"4GB\"                 # Memory available for the job \n",
    "                       , walltime='00:30:00'\n",
    "                       , local_directory=os.getcwd()  # Get current directory with os\n",
    "                       , log_directory=os.getcwd()   \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a2c74-70c1-406a-8a68-4faf4b07c8de",
   "metadata": {},
   "source": [
    "<div class=\"highlight_red\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ⚠ Note\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"content\">\n",
    "These are the characteristics of a simple task/worker running in a single node. When we create an object in this class Dask automatically sets up an template for a job script, which it later submits by choosing (scaling) the number of jobs with the command below. The cell above really just sets up the desired parameters.</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a69c6a65-6c22-4899-a603-5b4a96a7c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submits n jobs w/ the configuration above\n",
    "cluster.scale(jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07595d60-3b3d-4546-8219-df6007e5ae14",
   "metadata": {},
   "source": [
    "We can just the number of jobs, as shown above. However, it is also possible to specify either the number of workers, memory or cores. Dask will then choose the corresponding number of jobs. By using the ```job_script``` method we can get an idea of how things are working behind the scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af737354-ba35-49b0-a7bc-024631fc088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e Cluster/Jupyter-Gabriel/Dask-test//dask-worker-%J.err\n",
      "#SBATCH -o Cluster/Jupyter-Gabriel/Dask-test//dask-worker-%J.out\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=72\n",
      "#SBATCH --mem=4G\n",
      "#SBATCH -t 00:30:00\n",
      "\n",
      "/u/alvesgo/conda-envs/default_env/bin/python -m distributed.cli.dask_worker tcp://130.183.223.16:33457 --name dummy-name --nthreads 36 --memory-limit 1.86GiB --nworkers 2 --nanny --death-timeout 60 --local-directory Cluster/Jupyter-Gabriel/Dask-test/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b05499-fd17-4d86-8d84-cbb0c526aaec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "You can also check the status of these submissions through the terminal just to be sure that everything is working as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70edfac8-4b4f-4547-8a8d-2ba4947f38c4",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "raw_mimetype": "",
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# We can see the scheduled jobs running this terminal command:\n",
    "!squeue -u alvesgo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244de413-e957-4195-ad6d-00d5a9b19bcf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Node that this approach with Dask creates ```n_jobs```, so it is limited by the maximum number of running jobs on a Cluster (16 in the cluster used here). We should use other APIs, such as dask-mpi, in order to allocate multiple nodes per job. For instance, one might be interested in a single job which uses 50 nodes rather than 50 single node jobs. This might very well be your use case so feel free to check the last part of this notebook.\n",
    "\n",
    "Finally, note that the we can cleraly print the jobs/cluster information with the built-in functions in the library as as final check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de5609b2-9916-4fe7-b89b-523e8228ee3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://130.183.223.16:39785' processes=0 threads=0, memory=0 B>\n"
     ]
    }
   ],
   "source": [
    "# Connect to that cluster\n",
    "client = Client(cluster) \n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070158ff-7565-4494-bf0e-77ad7c23d0ab",
   "metadata": {},
   "source": [
    "Here we have used the ```Client``` class to establish a connection with the Dask cluster. Per the documentation:\n",
    "\n",
    "> It provides an asynchronous user interface around functions and futures.\n",
    "\n",
    "The _client_ is the central process where we controle everything. They receive the results from the _workers_.\n",
    "\n",
    "The graphical representation on notebooks is also very convenient. Here you can see the number of workers and their hardware specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b191f-b18a-42cd-91ad-49745ead3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e495dd3-8c85-464e-8efb-b572578f7d8e",
   "metadata": {},
   "source": [
    "<div class=\"highlight_green\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ❐ Dashboard\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "By accessing <a href=\"https://www.dask.org\">http://localhost:8787/status</a> you can find a very complete dashboard containing information about your ongoing jobs and workers. This <a href=~https://docs.dask.org/en/latest/dashboard.html~>page</a> from the documentation provides a nice overview.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df810b83-f797-47d1-b99a-4e6228a60efe",
   "metadata": {},
   "source": [
    "### Monte Carlo Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1525cc-807f-4655-9dd6-e53f43815ca9",
   "metadata": {},
   "source": [
    "First we define a function which assigns random $(x, y)$ coordinates to the column of a matrix. Each column is a \"realization\" of the MC method. We then divide this large matrix into chunks, which we send to the workers. For this we use the built-in array format, which is analogous to numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "50474220-468e-4319-8d57-003a09c92fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_coord_random(num_runs, num_chunks):\n",
    "\n",
    "    chunk_size = num_runs//num_chunks\n",
    "\n",
    "    # Returns a dask array with entries between 0 and run\n",
    "    return da.random.uniform(low=0, high=1, size=(2, num_runs), chunks=(2, chunk_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "48b4583d-72ca-444d-b03d-b3425c0ef871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 1.56 kiB </td>\n",
       "                        <td> 320 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (2, 100) </td>\n",
       "                        <td> (2, 20) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 5 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"79\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"29\" x2=\"120\" y2=\"29\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"29\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"29\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"29\" />\n",
       "  <line x1=\"72\" y1=\"0\" x2=\"72\" y2=\"29\" />\n",
       "  <line x1=\"96\" y1=\"0\" x2=\"96\" y2=\"29\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"29\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,29.030629010473877 0.0,29.030629010473877\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"49.030629\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >100</text>\n",
       "  <text x=\"140.000000\" y=\"14.515315\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,14.515315)\">2</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<uniform, shape=(2, 100), dtype=float64, chunksize=(2, 20), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_coord_random(100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "17c276bf-778c-4785-99ef-295a71f2da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Total number of monte carlo runs\n",
    "runs = 1e6\n",
    " \n",
    "def dask_array_MC(num_runs, num_chunks):\n",
    "    \"\"\"Computes pi with monte carlo simulations. Performs num_runs/num_chunks on each worker\"\"\"\n",
    "\n",
    "    # Generates the random coordinates in appropriate chunk sizes\n",
    "    xy_coordinates = xy_coord_random(num_runs, num_chunks) \n",
    "\n",
    "    # Computes the distance from the origin\n",
    "    distance_origin = (xy_coordinates ** 2).sum(axis=0)\n",
    "\n",
    "    # Counts the points within the circle\n",
    "    in_circle = (distance_origin < 1)\n",
    "\n",
    "    # Ratio area (slice of) circle/area square\n",
    "    pi = 4 * in_circle.mean()\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c1d20-73bc-45a5-ac15-c1ab0ba7f829",
   "metadata": {},
   "source": [
    "We can compute the serial time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "478ba860-8ef2-48de-a9a6-06bf7bae433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated value of pi for 1 chunks: 3.1428112\n",
      "CPU times: user 77.9 ms, sys: 0 ns, total: 77.9 ms\n",
      "Wall time: 489 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chunks = 1\n",
    "print(\"Estimated value of pi for\", chunks, \"chunks:\", dask_array_MC(runs, 1).compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72344d8-c56a-425a-90b7-aecda1eff682",
   "metadata": {},
   "source": [
    "Since we have $n$ workers, each worker will perform $10^6/n$ simulations. With our current parameters we have $n=16$ workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c18238ef-62f3-4b38-90bd-d9008d1eb67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated value of pi for 32 chunks: 3.1422432\n",
      "CPU times: user 67.8 ms, sys: 0 ns, total: 67.8 ms\n",
      "Wall time: 477 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chunks = 32\n",
    "print(\"Estimated value of pi for\", chunks, \"chunks:\", dask_array_MC(runs, 1).compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136601e-e0c4-4763-88f2-66b1ac857ad9",
   "metadata": {},
   "source": [
    "Note that using a larger number of chunks now _increases_ the wall time. We have more chunks than available workers, so many of these calculations will queue up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1e465c92-c0ef-4358-9492-0029e0256258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated value of pi for 128 chunks: 3.1410944\n",
      "CPU times: user 62.7 ms, sys: 90 µs, total: 62.8 ms\n",
      "Wall time: 444 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chunks = 128\n",
    "print(\"Estimated value of pi for\", chunks, \"chunks:\", dask_array_MC(runs, 1).compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f486dac-7d64-4653-bec4-c453b6989221",
   "metadata": {},
   "source": [
    "## dask.delayed  | Parallelizing a task with lazy evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5610094-031f-41c5-8797-5d610e898275",
   "metadata": {},
   "source": [
    "In this section we will show how to extract and use the results from calculations performed by different nodes and workers; centralizing all the peripheral computations.\n",
    "\n",
    "As example, we define three different matrices $A$, $B$ and $C$. We can parallelize a for loop containing the matrix operations using the interface ```dask.delayed(...)(...)```. This is a wrapper responsible for operating with the function in the _first_ argument in a lazy manner, while the arguments of the function of interest come into the second set of parantheses. The function will essentially build a task graph in the background with our function calls.\n",
    "\n",
    "- Actually, you can even use the usual decorator synthax in Python in order to avoid too much boiler plate when paralellizing stuff with Dask. <a href=\"https://docs.dask.org/en/stable/delayed.html#decorator\">Check this page</a>, and also [this one](https://docs.dask.org/en/latest/delayed-api.html) in the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8fa17e39-cbf3-47d8-afae-f41758745336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squares a matrix w/ matrix multiplication\n",
    "def squared(arr):\n",
    "    return arr@arr\n",
    "\n",
    "# Defines 3 random matrices of size n\n",
    "n=5000\n",
    "mat_A =  np.random.rand(n, n)\n",
    "mat_B =  np.random.rand(n, n)\n",
    "mat_C =  np.random.rand(n, n)\n",
    "\n",
    "# Output containing the (tokens/futures) for each squared value\n",
    "output = []\n",
    "\n",
    "# Passes the 'squared' to dask.delayed in order to paralellize it and then appends to the list\n",
    "for mat in [mat_A, mat_B, mat_C]:\n",
    "    mat = dask.delayed(squared)(mat) \n",
    "    output.append(mat)               \n",
    "\n",
    "# A + B + C using 'sum'\n",
    "total = dask.delayed(sum)(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91288f6-425a-465d-808d-8e3ff60287b7",
   "metadata": {},
   "source": [
    "Also, Note that the parallellzation stems from the fact that we are _simultaneously_ operating on the matrices $A$, $B$ and $C$. The internal steps of the matrix multiplication however are **not** parallel. The syntax here with ```dask.delayed(squared)``` might look a bit weird, but what is happening behind the scenes is just <a href=\"https://toolz.readthedocs.io/en/latest/curry.html\" >currying</a>. A lot of stuff happening is very functional! See also <a href=\"https://www.stratascratch.com/blog/go-to-guide-to-currying-in-python/\">this link</a> for more details.\n",
    "\n",
    "- An <a href=\"https://softwareengineering.stackexchange.com/questions/293851/what-is-it-about-functional-programming-that-makes-it-inherently-adapted-to-para\">excellent question on this topic </a> can be found in SE\n",
    "\n",
    "Regardless of the details, all these operations are done lazily, and when you access ```dask.delayed(...)(...)``` you get a _token_ pointing to the result of your calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "44f18944-1aa4-4555-a569-c93cb5028197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('sum-dbeeff7e-3d5a-4ff6-812e-b24a650dc822')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f77ed5-fc80-4404-9ba5-c9ce80f38d86",
   "metadata": {},
   "source": [
    "You can then use the method ```compute``` to get the numerical result, that is, a _concrete value_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ef3888e7-8e6d-405c-8285-6a2c5c0ea8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3751.96892472, 3744.5341925 , 3750.79766574, ..., 3772.88617264,\n",
       "        3710.84912013, 3760.78695976],\n",
       "       [3742.43949997, 3754.26777582, 3773.77063438, ..., 3767.1661149 ,\n",
       "        3735.62635214, 3760.77346046],\n",
       "       [3751.35205524, 3753.20059541, 3769.94835268, ..., 3766.99535821,\n",
       "        3722.44762785, 3788.21781464],\n",
       "       ...,\n",
       "       [3774.13223642, 3763.1392995 , 3784.17558326, ..., 3784.93699223,\n",
       "        3755.32813315, 3786.16227172],\n",
       "       [3777.17175516, 3769.73576613, 3787.77744033, ..., 3793.49471824,\n",
       "        3755.29158264, 3791.72912123],\n",
       "       [3705.88167301, 3740.14915976, 3741.3643459 , ..., 3736.84298373,\n",
       "        3701.47322593, 3748.37399958]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e208fa-0a61-439c-a956-73cc6a233e31",
   "metadata": {},
   "source": [
    "We can also get a **graph representation** of these lazy objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c0146-eee0-47ba-818c-b3383d2c2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887b149-8fd3-433f-890e-10841dda9020",
   "metadata": {},
   "source": [
    "We can clearly see that ``Delayed`` objects act as proxies for the object they wrap, but all operations on them are done lazily by building up a dask graph internally. Compare it with the standard computation ```mat_A@mat_A + mat_B@mat_B + mat_C@mat_C``` to verify that you would get the very same result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43109b-af57-420f-940d-2cdec09ea44a",
   "metadata": {},
   "source": [
    "### Comparison with serial code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b63af-31c9-4b16-8a44-55f74c30dcd1",
   "metadata": {},
   "source": [
    "Now we compare this with what we would get w/ non-parallel code. For that we will try to solve for the eigenvalues for a bunch of large matrices. Additionaly, since we can have at most ```n_jobs``` $\\times$```n_processes``` tasks (or workers) going on, this is the number of matrices we will try to diagonalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0581fc92-a3b8-4197-bb49-6cac3856ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_lst = [np.random.rand(n, n) for i in range(n_jobs*n_processes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd00ac-ae64-4654-b4f9-cc06878df630",
   "metadata": {},
   "source": [
    "The single node job naturally takes a while:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0805af40-39f6-433b-a60d-b758f338f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 25min 21s, sys: 6min 20s, total: 5h 31min 41s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Computation done on 72 cpus on an interactive node in the RAVEN Cluster\n",
    "output = []\n",
    "\n",
    "for mat in mat_lst:\n",
    "    output.append(np.linalg.eigvals(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbac689-a459-41b4-b80c-9e11a67d5137",
   "metadata": {},
   "source": [
    "By deploying the workers and paralellizing we get much faster results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a8f6e472-9e08-4be4-9f6d-f3eb514afb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/alvesgo/conda-envs/dask_env/lib/python3.12/site-packages/distributed/client.py:3169: UserWarning: Sending large graph of size 5.96 GiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.11 s, sys: 7.18 s, total: 13.3 s\n",
      "Wall time: 55.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.49960890e+03 +0.j        , -1.58445192e+01+13.16488534j,\n",
       "       -1.58445192e+01-13.16488534j, ...,  1.78548352e-01 -0.35003405j,\n",
       "       -4.11920976e-01 +0.36222131j, -4.11920976e-01 -0.36222131j])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output = []\n",
    "\n",
    "for mat in mat_lst:\n",
    "    # Lazy interfacing of np.linalg.eigvals\n",
    "    output.append(dask.delayed(np.linalg.eigvals)(mat))\n",
    "\n",
    "total = dask.delayed(output)\n",
    "\n",
    "# Starts the computation\n",
    "total = total.compute()\n",
    "\n",
    "# For concreteness, prints the first matrix\n",
    "total[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4c0c7-f717-4836-b836-5bbf1991ae64",
   "metadata": {},
   "source": [
    "## distributed.Future | The map/reduce paradigm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1278f28-e6f3-4593-ae32-c46276a9b7db",
   "metadata": {},
   "source": [
    "You might have noticed that we got some annoying (but very helpful) warning in the last section regarding the very large graphs. There is actually a small set of a few other very helpful functions for paralellization which will allow us to do some of these calculations more carefully, sometimes with less overhead.\n",
    "\n",
    "- See map, submit and gather in the <a href=\"https://distributed.dask.org/en/stable/quickstart.html\">quickstart page for the ```dask.distributed```</a> package. The <a href=\"https://distributed.dask.org/en/latest/client.html\">documentation on ```client```</a> also provides some valuable insight.\n",
    "\n",
    "<div class=\"highlight_blue\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ☞ Using futures\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "\n",
    "You can use the ```Submit``` and  ```Map```  to submit and perform remote calculations/functions in the distributed workers for **single or many tasks, respectively**. As mentioned before, these functions return just tokens, and no the computation result itself. Instead, the result is stored locally in the cluster. They can be retrieved with the ```Future.result``` or ```Client.gather``` methods.\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa4f5e7-b569-4f11-8164-f96c51165d4f",
   "metadata": {},
   "source": [
    "\n",
    "This <a href=\"https://distributed.dask.org/en/latest/client.html\">page on Client</a>, and more importantly, on <a href=\"https://docs.dask.org/en/latest/futures.html\">futures</a>, has a few important details on:\n",
    "\n",
    "- How future works and the purity of function calls\n",
    "- And about the Async/await operations and efficiency of computations\n",
    "- Besides, one important difference when compared to ```dask.delayed``` is that the evaluation is **immediate** (running in the background), **not lazy**\n",
    "\n",
    "This [short video](https://youtu.be/07EiCpdhtDE) provides a very pedagogical introduction. From the documentation itself:\n",
    "\n",
    "> \"You can pass futures as inputs to submit. Dask automatically handles dependency tracking; once all input futures have completed, they will be moved onto a single worker (if necessary), and then the computation that depends on them will be started.\"\n",
    "\n",
    "The future and keys are useful because they often avoid redundancy and computing the same thing over and over again. That is why it is important knowing that ```distribute``` **assumes that functions are pure by default**. One need to flag it as false otherwise!  And perhaps even more conveniently, you do not have to worry so much about dependency tracking, as outlined above -- this delegates a lot of the hardwork to the library! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b3f2f-4eb3-4d82-aa41-def7afea97b4",
   "metadata": {},
   "source": [
    "### An example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273fdf32-ce2a-4d71-a0d5-6c2c8c7cba3c",
   "metadata": {},
   "source": [
    "Let's do another silly example. We will square large matrices and then compute their eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3598673a-b13d-431b-b845-da00d1791a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.9 s, sys: 917 ms, total: 10.8 s\n",
      "Wall time: 9.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Redefines a new matrix list\n",
    "mat_lst = [np.random.rand(n, n) for i in range(n_jobs*n_processes)]\n",
    "\n",
    "# This is prepared in the scheduler (and then submited to the background):\n",
    "squared_mat_lst = client.map(squared, mat_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342213b-3869-4a2a-b813-a26420c36a10",
   "metadata": {},
   "source": [
    "We get a future object/a token pointing to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a2147222-ab0e-43bd-9676-321fba869046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Future: squared</strong>\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> status: </span>\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-error-color0, black)\">finished</span>,\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> type:</span> numpy.ndarray,\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> key:</span> squared-744d0d6a39dc881f4ef669633954d195"
      ],
      "text/plain": [
       "<Future: finished, type: numpy.ndarray, key: squared-744d0d6a39dc881f4ef669633954d195>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_lst[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3505576-7f36-4a2b-908b-e68dd33f1e17",
   "metadata": {},
   "source": [
    "We can retrieve it to the client with ```.result()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "492b4c78-6d50-44df-8eae-abdf9d1319d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1275.82259087, 1235.85577784, 1249.04106904, ..., 1237.84133264,\n",
       "        1243.03154767, 1260.15365486],\n",
       "       [1287.65928071, 1245.23824462, 1252.98365661, ..., 1263.70408106,\n",
       "        1255.99548535, 1273.9411894 ],\n",
       "       [1260.47477711, 1231.30376769, 1243.35862719, ..., 1233.05677994,\n",
       "        1230.9708148 , 1253.37178606],\n",
       "       ...,\n",
       "       [1279.23130428, 1248.45153704, 1257.19584802, ..., 1257.43233617,\n",
       "        1254.33921521, 1270.38945455],\n",
       "       [1275.23281068, 1246.66132112, 1245.23571806, ..., 1253.62257434,\n",
       "        1250.99371266, 1268.62430216],\n",
       "       [1268.98030849, 1236.69683326, 1239.72837433, ..., 1240.82074379,\n",
       "        1236.43997673, 1252.2041179 ]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_lst[0].result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a8c52-3eac-420b-ae0e-5a0636296819",
   "metadata": {},
   "source": [
    "You may see the Future above either as **pending** or **finished**, since the process is running in the background through the workers. Now we take this list of squared matrices ```squared_mat_lst``` and map ```np.linalg.eigvals``` over them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a493514-6c22-4d19-9784-1ea7d0c8d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Maps the function call\n",
    "mapped_eig_lst = client.map(np.linalg.eigvals, squared_mat_lst)\n",
    "\n",
    "# Gathers the list of futures with .gather()\n",
    "gathered_eig_lst = client.gather(mapped_eig_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50505c24-bc1a-4163-840d-7ce7cdefd21c",
   "metadata": {},
   "source": [
    "For concreteness, the first set of eigenvalues is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4e9d3-6dcd-4a9e-9db9-e451d13624e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gathered_eig_lst[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcae12-5ba7-4154-8b5b-81c4a0b3bd93",
   "metadata": {},
   "source": [
    "Finally, notice that ```gather``` retrieves data from the distributed workers. Meanwhile, ```Client.scatter```  does the reverse process: it scatters the local desired data to the distributed processes. When we do that we get a future pointing to that data. This might avoid an overhead of too much data movement. We discuss this in the next session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81404ee5-4a70-4e40-b766-07318525893a",
   "metadata": {},
   "source": [
    "<div class=\"highlight_green\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ❐ Remark\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "In short, the Dask workflow is very convenient, allowing for both <b>high level</b> and <b>low level</b> use:\n",
    "    \n",
    "- High level data structures which can be used out-of-the-box, such as the Dask arrays...\n",
    "- ...as well a lower level APIs, suck as ```dask.delayed```, which allow us to write more arbitrary parallel code.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d8610-1081-4d8f-b710-b1df41ea4128",
   "metadata": {},
   "source": [
    "## Data locality and managing memory | Scattering and moving large data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4d42b4-b386-4404-90d0-05c49ae1ea0d",
   "metadata": {},
   "source": [
    "### Submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738cbcfa-521c-426e-9e4b-2ae62c4d594c",
   "metadata": {},
   "source": [
    "<div class=\"highlight_blue\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ☞ Submitting tasks\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "\n",
    "As you have probably noticed in the previous examples, ```submit()``` is the routine used in ```dask.distributed``` to send _functions_ to workers, returning a _future_ object which corresponds to the async calculation running in the background in one of workers. The resulting future can be further handled by other Dask functionalities. On top of parallelizing and speeding up computations, ```submit()``` is also useful in managing memory when dealing with a distributed system.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56cba8-6f14-4402-8f25-2dd2526596d6",
   "metadata": {},
   "source": [
    "For this example, we will generate very large numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd98bd4-cfe6-48eb-9d1b-9684cb81257e",
   "metadata": {
    "scene__Default Scene": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "def random_matrix(n):\n",
    "    return np.random.rand(n,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3bcb9-b40c-4546-8096-6e5fe21d8fda",
   "metadata": {},
   "source": [
    "Now, let us define a function ```random_matrix(n)``` which computes $c \\mathrm{\\: Tr\\: } {\\bf M}$ given a matrix $\\bf M$ which is $n \\times n$ and a scalar $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8fc58c-44f7-4b9f-a02a-57eacc7c1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace of M times a constant\n",
    "def dask_trace(M, parameter=1):\n",
    "    return parameter*np.trace(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd8e79-222a-4567-91a6-762180320d23",
   "metadata": {},
   "source": [
    "If we try to generate a large matrix in the client and then send it to the workers through Dask, we'll get a warning when invoking a function by wrapping it with ```dask.delayed```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18cdd526-8cc5-41cf-b26a-c98ae027a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/alvesgo/conda-envs/dask_env/lib/python3.12/site-packages/distributed/client.py:3157: UserWarning: Sending large graph of size 32.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1021.1154255373143"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 2**11\n",
    "\n",
    "random_matrix_client = random_matrix(dim)\n",
    "dask.delayed(dask_trace)(random_matrix_client).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ba55e-6137-4451-83e6-5a6647c412ca",
   "metadata": {},
   "source": [
    "Which has more or less the same size as the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eea376dc-aedf-4d6c-83d4-159fa3baa113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix size (in Mb):  33.55456\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix size (in Mb): \", sys.getsizeof(random_matrix_client)/10**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde285e2-9abb-4a21-acf2-4e27b82cf200",
   "metadata": {},
   "source": [
    "This is specially annyoing if we want to, let's say, map this over several different workers. There is a lot of data movement involved. How to fix this? There are a lot of options.\n",
    "We we did in the previous section, we can just use ```submit``` -- which submits a _function application_, cobining it with ```delayed```. \n",
    "This command will make the scheduler tell one of the workers to execute the function ```random_matrix``` taking ```dim``` as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b22444ca-6761-4aa1-ae10-d701b5c2ffc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Future: random_matrix</strong>\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> status: </span>\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-error-color0, black)\">finished</span>,\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> type:</span> numpy.ndarray,\n",
       "\n",
       "\n",
       "<span style=\"color: var(--jp-ui-font-color2, gray)\"> key:</span> random_matrix-348c54211768a73645ab6145ec2398dc"
      ],
      "text/plain": [
       "<Future: finished, type: numpy.ndarray, key: random_matrix-348c54211768a73645ab6145ec2398dc>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrix_in_worker = client.submit(random_matrix, dim)\n",
    "random_matrix_in_worker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10168e-7406-4311-bf4e-c559d94eb7d1",
   "metadata": {},
   "source": [
    "Note that ```client.submit()``` takes a concrete value/normal python object and transforms it into a **future**. We could then retrieve the result with ```.result()```. For instance, we could use to retrieve the result back to the client and then just use the result for further computations. We could, let's say, take the trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e583820b-643e-46f0-be2c-b4f44ccd874f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016.4303913711992"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(random_matrix_in_worker.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f01630-4519-461a-9b38-9db2073ec063",
   "metadata": {},
   "source": [
    "However, bringing the result back to the scheduler is unnecessary. We can call the desired function lazily, as we did before. This is even better, since now we don't even need to bring the (large) intermediate result into play. We can just ask the worker to perform this computatation lazily, without ever bringing the matrix back to the client. After that we can simply use the ```.compute()``` method to evaluate the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ea2ba2c-3277-4ffe-b316-a85c40380fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('trace-c6ad9bf5-f213-4982-8370-f4b86c6aa6d6')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computation_in_worker = dask.delayed(np.trace)(random_matrix_in_worker)\n",
    "computation_in_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f0b25a5-f6e4-4c50-a6f1-a927ed070f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016.4303913711992"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computation_in_worker.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0ac51-bc99-466b-a293-6018d859360f",
   "metadata": {},
   "source": [
    "By being more careful we move much less data around and do not get the warning we had before!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e80716-c34c-4e19-bba8-a6ae6c7aaa59",
   "metadata": {},
   "source": [
    "### Scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf700228-375d-4ca5-9116-fdee0b4c4d26",
   "metadata": {},
   "source": [
    "<div class=\"highlight_blue\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ☞ Sending data from the client to the workers\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "\n",
    "Another very useful feature is the [data scattering](https://distributed.dask.org/en/stable/locality.html#data-scatter) functionality, which allows us to transmit and distribute data from the clients to the workers, which you can find in the linked documentation. This is very similar to the ```submit()``` method, and is even more important concerning the management of memory across the distributed system or local computer.\n",
    "\n",
    "\n",
    "If desired, it is possible data to specific workers. However, often we are also interested in sending the _same_ data to _all workers_. This is what we will do in this toy example. In this case we need the option ```broadcast=True```:\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "080020c1-9a88-4db0-84c1-025cdd7c771b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: finished, type: int, key: int-35dba5d75538a9bbe0b4da4422759a0e>,\n",
       " <Future: finished, type: int, key: int-beb4dbf9af069aa2df7b147229965085>,\n",
       " <Future: finished, type: int, key: int-f2577a6fc29b900fe7d4c6321346be48>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sends data to all workers\n",
    "scattered_futures = client.scatter([1, 2, 3], broadcast=True)  \n",
    "scattered_futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9f521-2eeb-42c4-a42e-a3abc69f8017",
   "metadata": {},
   "source": [
    "<div class=\"highlight_red\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ⚠ Note\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"content\">\n",
    "    \n",
    "- Note that while <code>submit()</code> sends a <b>function application</b>, <code>scatter()</code> sends  <b>data</b>\n",
    "- Both methods ```distributed.Client.submit() ``` and  <code>distributed.Client.scatter()</code> return **a future object**\n",
    "- Also, note that depending on preference or specific implementation, interfacing with <code>delayed()</code> might be prefered when working with a large computation graph\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c124a87-7079-4502-bfbe-b8cae1512713",
   "metadata": {},
   "source": [
    "As an example, let us, once again, use the random matrix ```random_matrix_client``` we had crated **locally** in the client. We can take this large amound of data and **send it to workers** so they can operate with it. This can be troublesome, since whenever the workers request the data we have to send it again -- so ```random_matrix_client``` is essentially being sent everytime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30da2a46-2737-42ff-b34b-b707af1b5ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/alvesgo/conda-envs/dask_env/lib/python3.12/site-packages/distributed/client.py:3157: UserWarning: Sending large graph of size 32.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/u/alvesgo/conda-envs/dask_env/lib/python3.12/site-packages/distributed/client.py:3157: UserWarning: Sending large graph of size 96.00 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(510.55771276865715, 1021.1154255373143, 2042.2308510746286)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maps the trace function on the local matrix created above with three different parameters as an argument\n",
    "mapped_results = client.map(lambda c : dask.delayed(dask_trace)(random_matrix_client, c), [0.5, 1, 2])\n",
    "dask.compute(*client.gather(mapped_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a3972-d664-4619-b204-0eebe18b01c8",
   "metadata": {},
   "source": [
    "In the code below we fix the problem, since by preemptively scattering the data among all workers, it is readily available to them. \n",
    "\n",
    "<div class=\"highlight_blue\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ☞ The trick\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "\n",
    "More concretely, this works as follows: the method ```client.scatter()``` will create a future, and all further computation will point to this future -- thus, there will be no excessive data movement like in the previous example. This is useful since without ```scatter()``` we might need to resend the data whenever it is requested by one of the workers, even with ```submit()``` and alike. So, by combining ```scatter()``` -- for transfering _data_ -- and the other methods we saw before, such as ```submit()```and ```delayed()``` -- for submitting _tasks and operations_, we can greatly improve memory management in our workflow:\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4569d59-61c9-43f3-8fb9-3a7107e3e5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.4189466208778, 1000.8378932417556, 2001.6757864835113)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scatters data among workers -- returns  list of futures\n",
    "scattered_matrix = client.scatter(random_matrix(dim), broadcast=True)  \n",
    "\n",
    "# Maps the function dask_trace over the data above, wrapping it with delayed\n",
    "mapped_results_scatter = client.map(lambda c : dask.delayed(dask_trace)(scattered_matrix, c), [0.5, 1, 2])\n",
    "\n",
    "# Gathers the results form the futures obtained from client.gather() -- which returns a list of delayed objects, then computes them objects w/ dask.compute()\n",
    "dask.compute(*client.gather(mapped_results_scatter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b709a-ac90-44cd-8a84-a9c8bcf656cf",
   "metadata": {},
   "source": [
    "Note that here we did not really get any warnings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc0cb3-cac2-4272-8406-6afbebe45d1b",
   "metadata": {},
   "source": [
    "### Manually operating with workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf6bb41-ec4e-4add-85f3-d2a10139db46",
   "metadata": {},
   "source": [
    "Finally, to conclude, we show how this can be done in a more manual fashion. With ```client.scheduler_info()['workers']``` we can get the address of each worker and then submit tasks to specific workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ceaae5a5-9c06-4aad-9426-04a9576ba2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tcp://127.0.0.1:38551', 'tcp://127.0.0.1:42935']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worker_addresses = client.scheduler_info()['workers'].keys()\n",
    "worker_addresses = list(worker_addresses)\n",
    "worker_addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404f017-333a-4fd8-9909-de7beeca3b76",
   "metadata": {},
   "source": [
    "<div class=\"highlight_red\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ⚠ Note\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"content\">\n",
    "    \n",
    "Data broadcasting with ```client.scatter()```, specially replicas, might be actually incompatible with the [active memory manager in Dask](https://distributed.dask.org/en/latest/active_memory_manager.html#reducereplicas). It must be manually disabled! See this [issue](https://github.com/dask/distributed/issues/8657) on Github.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21bede-3e19-4837-ad31-b8fa4af3bbf0",
   "metadata": {},
   "source": [
    "To test this, we scatter some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8a6af28-943b-4f48-978c-4e9eb1e12c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually stopping the active memory manager so data is truly scattered to ALL workers. Otherwise one of the workers will get it\n",
    "client.amm.stop()\n",
    "future = client.scatter(random_matrix(dim), broadcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea9713-2c08-4de4-8a01-55faf8587171",
   "metadata": {},
   "source": [
    "And ```client.who_has()``` let us see which workers have access to this future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8303f425-e38b-4899-8a4a-5dbc18bded62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Key</th>\n",
       "        <th>Copies</th>\n",
       "        <th>Workers</th>\n",
       "    </tr>\n",
       "\n",
       "    \n",
       "    <tr>\n",
       "        <td>ndarray-3e5b140800c226ec94d30d5d1014a9a6</td>\n",
       "        <td>2</td>\n",
       "        <td>tcp://127.0.0.1:42935, tcp://127.0.0.1:38551</td>\n",
       "    </tr>\n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "{'ndarray-3e5b140800c226ec94d30d5d1014a9a6': ('tcp://127.0.0.1:42935',\n",
       "  'tcp://127.0.0.1:38551')}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.who_has(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3cb66-b350-4528-94f8-b7cd1f7e6c8e",
   "metadata": {},
   "source": [
    "Note that **both** workers can access the matrix in ```future```. Had we passed the argument ```client.scatter(..., broadcast=False)```, only one worker would have gotten the data. These addresses can then be passed as parameters to other methods in the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ef536c1-a79b-40ed-a88e-1679a8cd4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions the toy example\n",
    "function_A = np.trace\n",
    "function_B = np.max\n",
    "function_C = np.min\n",
    "\n",
    "# Computes the trace\n",
    "computation_A = client.submit(function_A, future, workers=worker_addresses[0])\n",
    "\n",
    "# Computes the maximum\n",
    "computation_B = client.submit(function_B, future, workers=worker_addresses[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1ee0b-268a-4261-a13e-14e351a129ac",
   "metadata": {},
   "source": [
    "The first future is in the first client, while the second future in the second client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3741f9f1-cde9-435e-b41c-da8e86d07127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Key</th>\n",
       "        <th>Copies</th>\n",
       "        <th>Workers</th>\n",
       "    </tr>\n",
       "\n",
       "    \n",
       "    <tr>\n",
       "        <td>trace-1b32970dcbb17b553284755869faf8b9</td>\n",
       "        <td>1</td>\n",
       "        <td>tcp://127.0.0.1:38551</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <td>max-c80fd339a55195987a3f0ed1257f23ad</td>\n",
       "        <td>1</td>\n",
       "        <td>tcp://127.0.0.1:42935</td>\n",
       "    </tr>\n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "{'trace-1b32970dcbb17b553284755869faf8b9': ('tcp://127.0.0.1:38551',),\n",
       " 'max-c80fd339a55195987a3f0ed1257f23ad': ('tcp://127.0.0.1:42935',)}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.who_has([computation_A, computation_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8847be-8944-4b57-a884-367a09e4d7f0",
   "metadata": {},
   "source": [
    "Here we have used different functions in ```client.submit()``` in this toy example because Dask is actually quite smart about this: had we submitted the same function to be applied on the future, Dask would just point to the same fugure in both computations (remember the purity in Dask!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c02cb8f-16fe-4200-a365-119a95f89c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Key</th>\n",
       "        <th>Copies</th>\n",
       "        <th>Workers</th>\n",
       "    </tr>\n",
       "\n",
       "    \n",
       "    <tr>\n",
       "        <td>min-41181ac1d1cf5f8a69e8801e7da5c982</td>\n",
       "        <td>1</td>\n",
       "        <td>tcp://127.0.0.1:38551</td>\n",
       "    </tr>\n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "{'min-41181ac1d1cf5f8a69e8801e7da5c982': ('tcp://127.0.0.1:38551',)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computation_equal_1 = client.submit(function_C, future, workers=worker_addresses[0])\n",
    "computation_equal_2 = client.submit(function_C, future, workers=worker_addresses[1])\n",
    "client.who_has([computation_equal_1, computation_equal_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570baabe-9d66-438f-8e98-4fb45590e7cf",
   "metadata": {},
   "source": [
    "We can see in the result above both futures/computations are stored in the same worker. Finally, we can retrieve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f6f53f5-2e00-4988-a5b9-cae0cf974ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.5495096049874\n",
      "0.9999999861343417\n"
     ]
    }
   ],
   "source": [
    "print(client.gather(computation_A))\n",
    "print(client.gather(computation_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f57cb7-5d9b-4c36-9213-b9be89747405",
   "metadata": {},
   "source": [
    "<div class=\"highlight_green\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ❐ Remarks\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"content\">\n",
    "\n",
    "- One can find a good summary on ```map```, ```submit```, ```persist``` and ```compute``` on [on this post](https://medium.com/@mameralomari1/dask-map-submit-persist-compute-an-overview-of-differences-570a696e7158#:~:text=map%20allows%20you%20to%20apply,the%20result%20of%20the%20task.). Also refer back to the diagram in the beginning.\n",
    "- The overall concepts on data locality can also be found <a heref=\"https://distributed.dask.org/en/stable/locality.html\">in the documentation</a>\n",
    "- An alterntive we have not discussed here, which is similar to <code>compute()</code>, is the <code>persist()</code> method found in the link above. Acoording to the documentation:\n",
    "\n",
    "> \"This function is particularly useful when using distributed systems, because the results will be kept in distributed memory, rather than returned to the local process as with compute.\"\n",
    "\n",
    "- A very good point is also made [in this question](https://stackoverflow.com/questions/41806850/dask-difference-between-client-persist-and-client-compute):\n",
    "  \n",
    "> \"More pragmatically, I recommend using persist when your result is large and needs to be spread among many computers and using compute when your result is small and you want it on just one computer.\"\n",
    "\n",
    "- Overall, the difference between persist and compute can be found [in this part of the documentation](https://distributed.dask.org/en/stable/memory.html#:~:text=In%20this%20example,for%20fast%20analyses.). In short, ```compute()``` is blocking and returns the result to the host. This is dangerous if the computation is too large. Meanwhile, ```persist()```, as the name suggests, keeps the date in the distributed cluster. More concretely,  \n",
    "- Even using Dask, we can have a lot of fine-grained control. There are examples in the documentation where one can assigns different parts/steps in the computation to specific workers\n",
    "- This nice [question on Stack Overflow](https://stackoverflow.com/questions/41471248/how-to-efficiently-submit-tasks-with-large-arguments-in-dask-distributed) also provides a comprehensive\n",
    "   example.\n",
    "- ```client.run()``` can run the same function in all workers at once, but this returns in a dictionary and is done outside the scheduling system\n",
    "- One should be careful with the policy of reducing replicas in the [active memory management](https://distributed.dask.org/en/latest/active_memory_manager.html#reducereplicas)\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87964d4-faaa-4110-96e2-492e6de7f3e5",
   "metadata": {},
   "source": [
    "## Other scheduling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fc472-cc46-463c-bdeb-05f86edcdaf9",
   "metadata": {},
   "source": [
    "### A local client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9ace9-4273-40f5-9f0a-74d5f4746e67",
   "metadata": {},
   "source": [
    "It is also possible to set up **local workers** using ```distributed.deploy.local.LocalCluster```. This is useful when you do not need or do not have access to a full-fledged cluster/HPC systems and you still want to use the dask features -- which might be helpful nevertheless, even with a smaller number of cores and RAM available. All the commands you'd have to use in a proper cluster is the same, the only difference arises we deploy the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabc1015-e0fb-4afb-9b9d-530ec2b22744",
   "metadata": {
    "scene__Default Scene": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# Set up local cluster on your own machine/laptop\n",
    "cluster_local = LocalCluster(n_workers=2\n",
    "                             , threads_per_worker = 36\n",
    "                             , memory_limit=\"64GB\" \n",
    "                             , local_directory='data')    \n",
    "\n",
    "client = Client(cluster_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945a1d8-97ad-43f1-a54a-9fc23931ff8b",
   "metadata": {},
   "source": [
    "We can then check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9939c-ac58-4509-a426-23ced12a8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbe461-325d-4529-ade4-d7b168a3aed0",
   "metadata": {},
   "source": [
    "To close and delete; in order to fully reset everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23356d1e-ce54-47e3-89c6-0567828d277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()\n",
    "del(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b61ba92-06d8-44dc-bb46-d0ffcd5c86d7",
   "metadata": {},
   "source": [
    "### Dask and MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023f257-a333-4b14-8e09-fa57957fdd19",
   "metadata": {},
   "source": [
    "Finally, we focus on the [Dask-MPI package](https://docs.dask.org/en/stable/deploying-hpc.html#using-mpi), running it for [interactive jobs](https://mpi.dask.org/en/latest/interactive.html). This package allows us to use many nodes in a single job instead -- instead of sending a buch of different single-node jobs -- this might open up a few possibilities, specially if your cluster limits the number of concurrent jobs you can run, which can be a bottleneck for ```Dask.distributed```.\n",
    "\n",
    "<div class=\"highlight_red\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        ⚠ Note\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"content\">\n",
    "However, this time around we will use a slightly different workflow. The configuration might depend a lot on your current environment. I will perform this test, once again, for a cluster equipped with SLURM. This will be important for two reasons:\n",
    "\n",
    "- We will first have to **run the mpi command within a job script**, allocating the appropriate number of nodes and cores per node. We also want to match the number of mpi ranks in the command with the total number of cores\n",
    "- We have to be careful with the nannies depending on the MPI environment. See the warning [here](https://mpi.dask.org/en/latest/interactive.html#:~:text=MPI%20Jobs%20and%20Dask%20Nannies).\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4624e7b-e8c7-49b9-9b57-2be6c9f82001",
   "metadata": {},
   "source": [
    "Also note that we will only be using MPI to start the Dask cluster and not for inter-node communication.\n",
    "\n",
    "MPI packages might be readily available at your cluster, so be sure to check that beforehand. Nevertheless, we will install the [necessary packages](https://mpi4py.readthedocs.io/en/latest/install.html#using-conda) -- together with Dask-MPI, using ocnda:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge mpi4py openmpi dask-mpi\n",
    "```\n",
    "\n",
    "You can test whether your mpi installation is properly running with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d8cbe8e-bdb9-4870-8dc8-32e828408e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World! I am process 0 of 5 on raven05.\n",
      "Hello, World! I am process 1 of 5 on raven05.\n",
      "Hello, World! I am process 2 of 5 on raven05.\n",
      "Hello, World! I am process 3 of 5 on raven05.\n",
      "Hello, World! I am process 4 of 5 on raven05.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mpirun -n 5 python -m mpi4py.bench helloworld"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50187188-2cf9-4086-a5c8-135a887e210f",
   "metadata": {},
   "source": [
    "Once everything is setup, we can start the MPI process with a batch script. Here is an example:\n",
    "\n",
    "```\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "#SBATCH --job-name=dask_mpi_test\n",
    "#SBATCH -o ./out.%j\n",
    "#SBATCH -e ./err.%j\n",
    "#SBATCH -J dask-mpi-test\n",
    "#SBATCH -p general\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=8\n",
    "#SBATCH --mem=32GB\n",
    "#SBATCH -t 00:10:00\n",
    "#SBATCH --export=ALL          # Might be necessary to export env. varibles, making conda work\n",
    "\n",
    "# Activate Anaconda environment\n",
    "source activate dask_env\n",
    "\n",
    "# Run the MPI command\n",
    "mpirun -np 8 dask-mpi --worker-class distributed.Worker --scheduler-file scheduler.json\n",
    "```\n",
    "\n",
    "We can save this to a ```dask_mpi_test.job``` file and then submit the job:\n",
    "\n",
    "```\n",
    "sbatch dask_mpi_test.job\n",
    "```\n",
    "\n",
    "The number of ranks in the ```mpirun``` command matches the total number of cores from the job. We also activate our current conda environment before hand with ```source activate dask_env```. After everything is done, the file ```scheduler.json``` should appear in the appropriate directory. Since mpi has launched the clusters, Dask can now connect the client to the workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "662d8609-9afa-43e7-b3de-799b85e1670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(scheduler_file=os.getcwd() + '/scheduler.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d16713-18ce-46c6-9069-c9453593fe84",
   "metadata": {},
   "source": [
    "In my case I had to write down the absolute path. Further information and logs can be found on the output file of the job. Finally we can explicitly check whether we got the correct number of workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde688a-4740-4958-a890-fdb5a427d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4393a25b-901a-401e-8362-e31730736ad9",
   "metadata": {},
   "source": [
    "Finally, to close the client you can use the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aec849d9-f4de-423e-b68c-09ee8af1a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae19885-7ac4-41b0-afa9-53f7f0ac2de6",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958782b-de29-4fb3-a8f7-209fb10760b1",
   "metadata": {},
   "source": [
    "<div class=\"highlight_purple\">\n",
    "<div class=\"title_box\">\n",
    "    <div class=\"title\">\n",
    "        🕮 Further references\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div class=\"content\">\n",
    "\n",
    "\n",
    "- [1] Duke MIDS Fall 2023 Practical Data Science (IDS 720) Course, <a href=\"https://www.practicaldatascience.org/html/distributed_computing.html\">Distributed Computing with dask</a> </li>\n",
    "    \n",
    "- [2] Prabhakar Rangarao, <a href=\"https://prabhakar-rangarao.medium.com/distributed-computing-with-dask-8001e223df88\">Distributed Computing with Dask\n",
    "</a></li>\n",
    "\n",
    "- [3] Ciaron Linstead, <a href=\"https://gitlab.pik-potsdam.de/linstead/cluster-examples/-/tree/ea6db0986555fd5774753d402cb28e68bccc837b/python/dask\">Hybrid Python mpi4py + Dask example</a></li>\n",
    "\n",
    "- [4] <a href=\"https://docs.dask.org/en/latest/best-practices.html\">Dask Best Practices </a></li>\n",
    "- [5] @willirath, <a href=\"https://github.com/willirath/dask_jobqueue_workshop_materials\"> Workshop materials for a 4h course on Dask Jobqueue </a></li>\n",
    "- [6] Matthew Rocklin, <a href=\"https://blog.dask.org/2019/01/31/dask-mpi-experiment\"> Running Dask and MPI programs together -- an experiment</a></li>\n",
    "- [7] Sebastian B. Mohr, <a href=\"https://hps.vi4io.org/_media/teaching/autumn_term_2022/scap_sebastian_mohr_dask_performance.pdf\"> Dask performance </a></li>\n",
    "- [8] The [Dask documentation](https://docs.dask.org/en/stable/)\n",
    "- [9] The [dask.distributed API documentation](https://distributed.dask.org/en/stable/api.html)\n",
    "</div>    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask_kernel",
   "language": "python",
   "name": "dask_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "scenes_data": {
   "active_scene": "Default Scene",
   "init_scene": "",
   "scenes": [
    "Default Scene"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
