2024-04-05 16:36:10,647 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.181.85.156:39255'
2024-04-05 16:36:10,726 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.181.85.156:39695'
2024-04-05 16:36:16,059 - distributed.worker - INFO -       Start worker at:  tcp://10.181.85.156:43485
2024-04-05 16:36:16,059 - distributed.worker - INFO -          Listening to:  tcp://10.181.85.156:43485
2024-04-05 16:36:16,059 - distributed.worker - INFO -           Worker name:           SLURMCluster-3-0
2024-04-05 16:36:16,059 - distributed.worker - INFO -          dashboard at:        10.181.85.156:36987
2024-04-05 16:36:16,059 - distributed.worker - INFO - Waiting to connect to: tcp://130.183.162.116:46793
2024-04-05 16:36:16,060 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:36:16,060 - distributed.worker - INFO -               Threads:                         36
2024-04-05 16:36:16,060 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-04-05 16:36:16,060 - distributed.worker - INFO -       Local Directory: /raven/u/alvesgo/Cluster/Jupyter-Gabriel/dask-tutorial-hpc/Cluster/Jupyter-Gabriel/Dask-test/dask-scratch-space/worker-4us2gt26
2024-04-05 16:36:16,060 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:36:16,097 - distributed.worker - INFO -       Start worker at:  tcp://10.181.85.156:33541
2024-04-05 16:36:16,097 - distributed.worker - INFO -          Listening to:  tcp://10.181.85.156:33541
2024-04-05 16:36:16,097 - distributed.worker - INFO -           Worker name:           SLURMCluster-3-1
2024-04-05 16:36:16,097 - distributed.worker - INFO -          dashboard at:        10.181.85.156:42883
2024-04-05 16:36:16,097 - distributed.worker - INFO - Waiting to connect to: tcp://130.183.162.116:46793
2024-04-05 16:36:16,097 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:36:16,097 - distributed.worker - INFO -               Threads:                         36
2024-04-05 16:36:16,097 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-04-05 16:36:16,097 - distributed.worker - INFO -       Local Directory: /raven/u/alvesgo/Cluster/Jupyter-Gabriel/dask-tutorial-hpc/Cluster/Jupyter-Gabriel/Dask-test/dask-scratch-space/worker-6jo4a_9o
2024-04-05 16:36:16,097 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:36:24,179 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-05 16:36:24,180 - distributed.worker - INFO -         Registered to: tcp://130.183.162.116:46793
2024-04-05 16:36:24,181 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:36:24,182 - distributed.core - INFO - Starting established connection to tcp://130.183.162.116:46793
2024-04-05 16:36:24,183 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-05 16:36:24,184 - distributed.worker - INFO -         Registered to: tcp://130.183.162.116:46793
2024-04-05 16:36:24,184 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:36:24,186 - distributed.core - INFO - Starting established connection to tcp://130.183.162.116:46793
2024-04-05 16:41:34,082 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 1.36 GiB -- Worker memory limit: 1.86 GiB
2024-04-05 16:41:34,369 - distributed.worker.memory - WARNING - Worker is at 80% memory usage. Pausing worker.  Process memory: 1.50 GiB -- Worker memory limit: 1.86 GiB
2024-04-05 16:41:34,610 - distributed.nanny.memory - WARNING - Worker tcp://10.181.85.156:33541 (pid=16882) exceeded 95% memory budget. Restarting...
2024-04-05 16:41:34,651 - distributed.nanny - INFO - Worker process 16882 was killed by signal 15
2024-04-05 16:41:34,662 - distributed.nanny - WARNING - Restarting worker
2024-04-05 16:41:35,364 - distributed.diskutils - INFO - Found stale lock file and directory '/raven/u/alvesgo/Cluster/Jupyter-Gabriel/dask-tutorial-hpc/Cluster/Jupyter-Gabriel/Dask-test/dask-scratch-space/worker-waxsgoej', purging
2024-04-05 16:41:35,413 - distributed.diskutils - INFO - Found stale lock file and directory '/raven/u/alvesgo/Cluster/Jupyter-Gabriel/dask-tutorial-hpc/Cluster/Jupyter-Gabriel/Dask-test/dask-scratch-space/worker-2lb7fmlo', purging
2024-04-05 16:41:35,845 - distributed.worker - INFO -       Start worker at:  tcp://10.181.85.156:33621
2024-04-05 16:41:35,845 - distributed.worker - INFO -          Listening to:  tcp://10.181.85.156:33621
2024-04-05 16:41:35,845 - distributed.worker - INFO -           Worker name:           SLURMCluster-3-1
2024-04-05 16:41:35,845 - distributed.worker - INFO -          dashboard at:        10.181.85.156:39765
2024-04-05 16:41:35,845 - distributed.worker - INFO - Waiting to connect to: tcp://130.183.162.116:46793
2024-04-05 16:41:35,845 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:41:35,845 - distributed.worker - INFO -               Threads:                         36
2024-04-05 16:41:35,845 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-04-05 16:41:35,845 - distributed.worker - INFO -       Local Directory: /raven/u/alvesgo/Cluster/Jupyter-Gabriel/dask-tutorial-hpc/Cluster/Jupyter-Gabriel/Dask-test/dask-scratch-space/worker-r4ddqy2_
2024-04-05 16:41:35,845 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:41:36,387 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 1.31 GiB -- Worker memory limit: 1.86 GiB
2024-04-05 16:41:36,400 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-05 16:41:36,400 - distributed.worker - INFO -         Registered to: tcp://130.183.162.116:46793
2024-04-05 16:41:36,401 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:41:36,401 - distributed.core - INFO - Starting established connection to tcp://130.183.162.116:46793
2024-04-05 16:41:36,781 - distributed.worker.memory - WARNING - Worker is at 81% memory usage. Pausing worker.  Process memory: 1.52 GiB -- Worker memory limit: 1.86 GiB
2024-04-05 16:41:36,910 - distributed.nanny.memory - WARNING - Worker tcp://10.181.85.156:43485 (pid=16885) exceeded 95% memory budget. Restarting...
2024-04-05 16:41:36,944 - distributed.nanny - INFO - Worker process 16885 was killed by signal 15
2024-04-05 16:41:36,950 - distributed.nanny - WARNING - Restarting worker
2024-04-05 16:41:37,993 - distributed.worker - INFO -       Start worker at:  tcp://10.181.85.156:39981
2024-04-05 16:41:37,993 - distributed.worker - INFO -          Listening to:  tcp://10.181.85.156:39981
2024-04-05 16:41:37,993 - distributed.worker - INFO -           Worker name:           SLURMCluster-3-0
2024-04-05 16:41:37,993 - distributed.worker - INFO -          dashboard at:        10.181.85.156:41903
2024-04-05 16:41:37,993 - distributed.worker - INFO - Waiting to connect to: tcp://130.183.162.116:46793
2024-04-05 16:41:37,993 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:41:37,993 - distributed.worker - INFO -               Threads:                         36
2024-04-05 16:41:37,993 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-04-05 16:41:37,993 - distributed.worker - INFO -       Local Directory: /raven/u/alvesgo/Cluster/Jupyter-Gabriel/dask-tutorial-hpc/Cluster/Jupyter-Gabriel/Dask-test/dask-scratch-space/worker-noqu96c8
2024-04-05 16:41:37,993 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:41:38,503 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-04-05 16:41:38,503 - distributed.worker - INFO -         Registered to: tcp://130.183.162.116:46793
2024-04-05 16:41:38,503 - distributed.worker - INFO - -------------------------------------------------
2024-04-05 16:41:38,504 - distributed.core - INFO - Starting established connection to tcp://130.183.162.116:46793
slurmstepd: error: *** JOB 9964611 ON ravc2372 CANCELLED AT 2024-04-05T17:06:20 DUE TO TIME LIMIT ***
